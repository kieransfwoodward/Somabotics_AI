{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def convert_multiperson_data(input_csv, output_dir='joint_data'):\n",
        "\n",
        "    print(f\"Processing data from {input_csv}\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Get unique persons\n",
        "    persons = df['Person'].unique()\n",
        "\n",
        "    print(f\"Found {len(persons)} person(s) in the data\")\n",
        "\n",
        "    # Define the 7 key joints we want to track (mapped to MediaPipe landmarks)\n",
        "    # MediaPipe pose has 33 landmarks: https://developers.google.com/mediapipe/solutions/vision/pose_landmarker\n",
        "    joint_mapping = {\n",
        "        'Position1': 'Body_17',  # finger\n",
        "        'Position2': 'Body_15',  # wrist\n",
        "        'Position3': 'Body_13',  # elbow\n",
        "        'Position4': 'Body_11',  # shoulder\n",
        "        'Position5': 'Body_23',  # hip\n",
        "        'Position6': 'Body_25',  # knee\n",
        "        'Position7': 'Body_27'    # ankle\n",
        "    }\n",
        "\n",
        "    # Process each person separately\n",
        "    for person_id in persons:\n",
        "        person_df = df[df['Person'] == person_id]\n",
        "\n",
        "        # Get all frames for this person\n",
        "        frames = sorted(person_df['Frame'].unique())\n",
        "\n",
        "        # Initialize a new dataframe for clean data\n",
        "        clean_data = {'Frame': frames}\n",
        "\n",
        "        # Extract each joint position\n",
        "        for joint_name, landmark_name in joint_mapping.items():\n",
        "            joint_data = person_df[person_df['Landmark'] == landmark_name]\n",
        "\n",
        "            # Initialize with NaN\n",
        "            clean_data[f'{joint_name}'] = np.nan\n",
        "\n",
        "            # Map frame numbers to joint positions\n",
        "            frame_to_position = {}\n",
        "\n",
        "            for _, row in joint_data.iterrows():\n",
        "                frame = row['Frame']\n",
        "                # Store 3D position as a tuple\n",
        "                frame_to_position[frame] = (row['x'], row['y'], row['z'])\n",
        "\n",
        "            # Fill in positions for each frame\n",
        "            positions = []\n",
        "            for frame in frames:\n",
        "                if frame in frame_to_position:\n",
        "                    # Get the 3D position\n",
        "                    pos = frame_to_position[frame]\n",
        "                    positions.append(pos)\n",
        "                else:\n",
        "                    positions.append((np.nan, np.nan, np.nan))\n",
        "\n",
        "            # Convert to numpy for easier velocity calculation\n",
        "            np_positions = np.array(positions)\n",
        "\n",
        "\n",
        "            # Store the position magnitudes (distance from origin)\n",
        "            position_magnitudes = np.sqrt(np.sum(np_positions**2, axis=1))\n",
        "\n",
        "            # Update the dataframe\n",
        "            clean_data[f'{joint_name}'] = position_magnitudes\n",
        "            # clean_data[f'Velocity{joint_name[-1]}'] = velocities\n",
        "\n",
        "        # Create dataframe and fill missing values\n",
        "        clean_df = pd.DataFrame(clean_data)\n",
        "        clean_df = clean_df.interpolate(method='linear')\n",
        "\n",
        "        # Save to CSV\n",
        "        output_file = os.path.join(output_dir, f'human_person_{person_id}_joints.csv')\n",
        "        clean_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"Saved data for person {person_id} to {output_file}\")\n",
        "\n",
        "        # Optional: Visualize the joint positions\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for i in range(1, 8):\n",
        "            plt.plot(clean_df['Frame'], clean_df[f'Position{i}'], label=f'Joint {i}')\n",
        "        plt.title(f'Joint Positions - Person {person_id}')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Position (magnitude)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(output_dir, f'positions_person_{person_id}.png'))\n",
        "        plt.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tkSlBHeq5g-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_multiperson_data('MultipeopleData.csv')\n",
        "\n",
        "# convert_single_person_data('pose_arm_timeseries_Singleperson.csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYnjolvq5ijS",
        "outputId": "f8cf0737-b2f8-4ea7-f6d6-e0ebc7c048f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data from MultipeopleData.csv\n",
            "Found 1 person(s) in the data\n",
            "Saved data for person 1 to joint_data/human_person_1_joints.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftpmnFcc5o5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDsylPQN1rKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKazRevl1rMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6R7A6Z8p1rN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6s2w8PQW1rPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0koLwpg11rRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfpPe4kY1rTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy import signal, interpolate\n",
        "\n",
        "def convert_multiperson_data(input_csv, output_dir='joint_data', target_fps=20, source_fps=30):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    df = pd.read_csv(input_csv)\n",
        "    persons = df['Person'].unique()\n",
        "    print(f\"Found {len(persons)} person(s) in the data\")\n",
        "\n",
        "    # Define the 7 key joints we want to track (mapped to MediaPipe landmarks)\n",
        "    joint_mapping = {\n",
        "        'Position1': 'Body_17',  # finger\n",
        "        'Position2': 'Body_15',  # wrist\n",
        "        'Position3': 'Body_13',  # elbow\n",
        "        'Position4': 'Body_11',  # shoulder\n",
        "        'Position5': 'Body_23',  # hip\n",
        "        'Position6': 'Body_25',  # knee\n",
        "        'Position7': 'Body_27'   # ankle\n",
        "    }\n",
        "\n",
        "    # Process each person separately\n",
        "    for person_id in persons:\n",
        "        person_df = df[df['Person'] == person_id]\n",
        "\n",
        "        # Get all frames for this person\n",
        "        frames = sorted(person_df['Frame'].unique())\n",
        "\n",
        "        # Initialize a new dataframe for clean data\n",
        "        clean_data = {'Frame': frames}\n",
        "\n",
        "        # Extract each joint position\n",
        "        for joint_name, landmark_name in joint_mapping.items():\n",
        "            joint_data = person_df[person_df['Landmark'] == landmark_name]\n",
        "\n",
        "            clean_data[f'{joint_name}'] = np.nan\n",
        "            frame_to_position = {}\n",
        "\n",
        "            for _, row in joint_data.iterrows():\n",
        "                frame = row['Frame']\n",
        "                frame_to_position[frame] = (row['x'], row['y'], row['z'])\n",
        "\n",
        "            positions = []\n",
        "            for frame in frames:\n",
        "                if frame in frame_to_position:\n",
        "                    pos = frame_to_position[frame]\n",
        "                    positions.append(pos)\n",
        "                else:\n",
        "                    positions.append((np.nan, np.nan, np.nan))\n",
        "\n",
        "            np_positions = np.array(positions)\n",
        "\n",
        "            # Store the position magnitudes (distance from origin)\n",
        "            position_magnitudes = np.sqrt(np.sum(np_positions**2, axis=1))\n",
        "            clean_data[f'{joint_name}'] = position_magnitudes\n",
        "\n",
        "        clean_df = pd.DataFrame(clean_data)\n",
        "        clean_df = clean_df.interpolate(method='linear')\n",
        "\n",
        "        downsampled_df = downsample_dataframe(clean_df, source_fps, target_fps)\n",
        "\n",
        "        output_file = os.path.join(output_dir, f'3human_person_{person_id}_joints_{target_fps}hz.csv')\n",
        "        downsampled_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"Saved data for person {person_id} to {output_file}\")\n"
      ],
      "metadata": {
        "id": "3nRr25d51rUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_dataframe(df, source_fps, target_fps):\n",
        "    downsample_factor = source_fps / target_fps\n",
        "\n",
        "    if downsample_factor == 1:\n",
        "        return df\n",
        "\n",
        "    original_frames = df['Frame'].values\n",
        "    n_frames_new = int(len(original_frames) / downsample_factor)\n",
        "\n",
        "    position_cols = [col for col in df.columns if col.startswith('Position')]\n",
        "    downsampled_data = {'Frame': np.arange(n_frames_new)}\n",
        "\n",
        "    original_time = np.arange(len(df)) / source_fps\n",
        "    new_time = np.arange(n_frames_new) / target_fps\n",
        "\n",
        "    for col in position_cols:\n",
        "        interpolated = interpolate.interp1d(\n",
        "            original_time,\n",
        "            df[col].values,\n",
        "            kind='linear',\n",
        "            bounds_error=False,\n",
        "            fill_value='extrapolate'\n",
        "        )\n",
        "\n",
        "        downsampled_data[col] = interpolated(new_time)\n",
        "\n",
        "    downsampled_df = pd.DataFrame(downsampled_data)\n",
        "\n",
        "    return downsampled_df"
      ],
      "metadata": {
        "id": "vVo6iRLD1wu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_multiperson_data(\n",
        "    input_csv='MultipeopleData3.csv',\n",
        "    output_dir='joint_data',\n",
        "    target_fps=20,  # Target frame rate\n",
        "    source_fps=30   # Original frame rate\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T9f5EpL1szo",
        "outputId": "3c7b07a5-79d1-44f2-ec3f-e192b33180ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data from MultipeopleData3.csv\n",
            "Downsampling from 30Hz to 20Hz\n",
            "Found 1 person(s) in the data\n",
            "Saved data for person 1 to joint_data/3human_person_1_joints_20hz.csv\n",
            "Original frames: 6244, Downsampled frames: 4162\n",
            "Conversion and downsampling complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6MfaEubIJgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8aNINrCIJim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "515U-B3HIJk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZnXGCiwIJnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HDINy_1UIJpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7dGisilIJrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8lbXSFLIJtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T730rTOyIJvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nd2f-uzwIJxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdjRV6FjIJzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLmbrQDBIJ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0I4upIErIJ3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn-ill4DIJ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct conversion between XYZ and Radians\n"
      ],
      "metadata": {
        "id": "pmSOAYK5KVIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy import signal, interpolate\n",
        "\n",
        "def convert_multiperson_data(input_csv, output_dir='joint_data', target_fps=20, source_fps=30, normalize=True):\n",
        "    print(f\"Processing data from {input_csv}\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Get unique persons\n",
        "    persons = df['Person'].unique()\n",
        "\n",
        "    print(f\"Found {len(persons)} person(s) in the data\")\n",
        "\n",
        "    # Define the 7 key joints we want to track (mapped to MediaPipe landmarks)\n",
        "    joint_mapping = {\n",
        "        'Position1': 'Body_17',  # finger\n",
        "        'Position2': 'Body_15',  # wrist\n",
        "        'Position3': 'Body_13',  # elbow\n",
        "        'Position4': 'Body_11',  # shoulder\n",
        "        'Position5': 'Body_23',  # hip\n",
        "        'Position6': 'Body_25',  # knee\n",
        "        'Position7': 'Body_27'   # ankle\n",
        "    }\n",
        "\n",
        "    # Process each person separately\n",
        "    for person_id in persons:\n",
        "        person_df = df[df['Person'] == person_id]\n",
        "\n",
        "        # Get all frames for this person\n",
        "        frames = sorted(person_df['Frame'].unique())\n",
        "\n",
        "        # Initialize a new dataframe for clean data\n",
        "        clean_data = {'Frame': frames}\n",
        "\n",
        "        # Dictionary to store joint positions per frame\n",
        "        joints_3d = {}\n",
        "        for joint_name in joint_mapping.keys():\n",
        "            joints_3d[joint_name] = []\n",
        "\n",
        "        # Extract each joint 3D position\n",
        "        for frame in frames:\n",
        "            frame_joints = {}\n",
        "\n",
        "            # Initialize with None\n",
        "            for joint_name in joint_mapping.keys():\n",
        "                frame_joints[joint_name] = None\n",
        "\n",
        "            # Find landmarks for this frame\n",
        "            frame_data = person_df[person_df['Frame'] == frame]\n",
        "\n",
        "            # Extract joint positions\n",
        "            for joint_name, landmark_name in joint_mapping.items():\n",
        "                joint_row = frame_data[frame_data['Landmark'] == landmark_name]\n",
        "\n",
        "                if not joint_row.empty:\n",
        "                    # Get 3D position\n",
        "                    x, y, z = joint_row['x'].values[0], joint_row['y'].values[0], joint_row['z'].values[0]\n",
        "                    frame_joints[joint_name] = (x, y, z)\n",
        "\n",
        "            # Add to joints_3d\n",
        "            for joint_name, pos in frame_joints.items():\n",
        "                joints_3d[joint_name].append(pos)\n",
        "\n",
        "        # Calculate joint angles - This is the key improvement\n",
        "        joint_angles = calculate_joint_angles(joints_3d)\n",
        "\n",
        "        # Add to clean_data\n",
        "        for joint_name, angles in joint_angles.items():\n",
        "            clean_data[joint_name] = angles\n",
        "\n",
        "        # Create dataframe and fill missing values\n",
        "        clean_df = pd.DataFrame(clean_data)\n",
        "        clean_df = clean_df.interpolate(method='linear')\n",
        "\n",
        "        # Calculate velocities (optional)\n",
        "        for joint_name in joint_mapping.keys():\n",
        "            pos = clean_df[joint_name].values\n",
        "            # Simple velocity calculation (derivative)\n",
        "            vel = np.zeros_like(pos)\n",
        "            vel[1:] = np.diff(pos)\n",
        "            # Scale by fps to get proper units\n",
        "            vel = vel * source_fps\n",
        "            clean_df[f'Velocity{joint_name[-1]}'] = vel\n",
        "\n",
        "        # Normalize joint values to match robot range if requested\n",
        "        if normalize:\n",
        "            clean_df = normalize_joint_ranges(clean_df, joint_mapping)\n",
        "\n",
        "        # Downsample to target fps\n",
        "        downsampled_df = downsample_dataframe(clean_df, source_fps, target_fps)\n",
        "\n",
        "        # Save to CSV\n",
        "        output_file = os.path.join(output_dir, f'human_person_{person_id}_joints_{target_fps}hz.csv')\n",
        "        downsampled_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"Saved data for person {person_id} to {output_file}\")\n",
        "        print(f\"Original frames: {len(clean_df)}, Downsampled frames: {len(downsampled_df)}\")\n",
        "\n",
        "        # Visualize the joint angles\n",
        "        visualize_joint_data(downsampled_df, person_id, output_dir)\n",
        "\n",
        "def calculate_joint_angles(joints_3d):\n",
        "    \"\"\"\n",
        "    Calculate joint angles from 3D joint positions\n",
        "    This approximates the robot joint angles\n",
        "\n",
        "    Args:\n",
        "        joints_3d: Dictionary of joint positions (x,y,z) for each frame\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of joint angles for each frame\n",
        "    \"\"\"\n",
        "    joint_angles = {}\n",
        "\n",
        "    # Initialize joint angles\n",
        "    for joint_name in joints_3d.keys():\n",
        "        joint_angles[joint_name] = []\n",
        "\n",
        "    # Process each frame\n",
        "    n_frames = len(joints_3d['Position1'])\n",
        "\n",
        "    for frame in range(n_frames):\n",
        "        # Get joint positions for this frame\n",
        "        pos1 = joints_3d['Position1'][frame]  # finger\n",
        "        pos2 = joints_3d['Position2'][frame]  # wrist\n",
        "        pos3 = joints_3d['Position3'][frame]  # elbow\n",
        "        pos4 = joints_3d['Position4'][frame]  # shoulder\n",
        "        pos5 = joints_3d['Position5'][frame]  # hip\n",
        "        pos6 = joints_3d['Position6'][frame]  # knee\n",
        "        pos7 = joints_3d['Position7'][frame]  # ankle\n",
        "\n",
        "        # Skip if any joint position is missing\n",
        "        if None in [pos1, pos2, pos3, pos4, pos5, pos6, pos7]:\n",
        "            for joint_name in joint_angles.keys():\n",
        "                joint_angles[joint_name].append(np.nan)\n",
        "            continue\n",
        "\n",
        "        # Calculate angles\n",
        "        # These calculations are simplified approximations of joint angles\n",
        "\n",
        "        # Position1: Finger angle (relative to wrist)\n",
        "        finger_vec = np.array(pos1) - np.array(pos2)\n",
        "        wrist_vec = np.array(pos2) - np.array(pos3)\n",
        "        angle1 = angle_between_vectors(finger_vec, wrist_vec)\n",
        "\n",
        "        # Position2: Wrist angle (relative to elbow)\n",
        "        wrist_vec = np.array(pos2) - np.array(pos3)\n",
        "        elbow_vec = np.array(pos3) - np.array(pos4)\n",
        "        angle2 = angle_between_vectors(wrist_vec, elbow_vec)\n",
        "\n",
        "        # Position3: Elbow angle (relative to shoulder)\n",
        "        elbow_vec = np.array(pos3) - np.array(pos4)\n",
        "        shoulder_vec = np.array(pos4) - np.array(pos5)\n",
        "        angle3 = angle_between_vectors(elbow_vec, shoulder_vec)\n",
        "\n",
        "        # Position4: Shoulder angle (3D orientation)\n",
        "        # Using angle with vertical axis\n",
        "        vertical = np.array([0, 1, 0])  # Assuming Y is vertical\n",
        "        angle4 = angle_between_vectors(shoulder_vec, vertical)\n",
        "\n",
        "        # Position5: Hip angle\n",
        "        hip_vec = np.array(pos5) - np.array(pos6)\n",
        "        angle5 = angle_between_vectors(hip_vec, vertical)\n",
        "\n",
        "        # Position6: Knee angle\n",
        "        knee_vec = np.array(pos6) - np.array(pos7)\n",
        "        angle6 = angle_between_vectors(knee_vec, hip_vec)\n",
        "\n",
        "        # Position7: Ankle angle (orientation)\n",
        "        # Approximated as the angle with the ground plane normal\n",
        "        ground_normal = np.array([0, 0, 1])  # Assuming Z is up from ground\n",
        "        angle7 = angle_between_vectors(knee_vec, ground_normal)\n",
        "\n",
        "        # Add to joint angles\n",
        "        joint_angles['Position1'].append(angle1)\n",
        "        joint_angles['Position2'].append(angle2)\n",
        "        joint_angles['Position3'].append(angle3)\n",
        "        joint_angles['Position4'].append(angle4)\n",
        "        joint_angles['Position5'].append(angle5)\n",
        "        joint_angles['Position6'].append(angle6)\n",
        "        joint_angles['Position7'].append(angle7)\n",
        "\n",
        "    return joint_angles\n",
        "\n",
        "def angle_between_vectors(v1, v2):\n",
        "    \"\"\"\n",
        "    Calculate the angle between two vectors in 3D space\n",
        "\n",
        "    Args:\n",
        "        v1: First vector\n",
        "        v2: Second vector\n",
        "\n",
        "    Returns:\n",
        "        Angle in radians\n",
        "    \"\"\"\n",
        "    # Ensure vectors are numpy arrays\n",
        "    v1 = np.array(v1)\n",
        "    v2 = np.array(v2)\n",
        "\n",
        "    # Normalize vectors\n",
        "    v1_norm = np.linalg.norm(v1)\n",
        "    v2_norm = np.linalg.norm(v2)\n",
        "\n",
        "    # Check for zero vectors\n",
        "    if v1_norm < 1e-10 or v2_norm < 1e-10:\n",
        "        return 0.0\n",
        "\n",
        "    v1 = v1 / v1_norm\n",
        "    v2 = v2 / v2_norm\n",
        "\n",
        "    # Calculate angle\n",
        "    dot_product = np.clip(np.dot(v1, v2), -1.0, 1.0)\n",
        "    angle = np.arccos(dot_product)\n",
        "\n",
        "    return angle\n",
        "\n",
        "def normalize_joint_ranges(df, joint_mapping):\n",
        "    \"\"\"\n",
        "    Normalize joint angles to match robot joint ranges\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with joint angles\n",
        "        joint_mapping: Dictionary mapping joint names to landmarks\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with normalized joint angles\n",
        "    \"\"\"\n",
        "    # Example robot joint ranges (in radians)\n",
        "    # These should be adjusted based on your specific robot\n",
        "    robot_ranges = {\n",
        "        'Position1': (-2.9, 2.9),    # Joint 1\n",
        "        'Position2': (-1.8, 1.8),    # Joint 2\n",
        "        'Position3': (-2.9, 2.9),    # Joint 3\n",
        "        'Position4': (-3.1, 0.0),    # Joint 4\n",
        "        'Position5': (-2.9, 2.9),    # Joint 5\n",
        "        'Position6': (-0.0, 3.8),    # Joint 6\n",
        "        'Position7': (-2.9, 2.9)     # Joint 7\n",
        "    }\n",
        "\n",
        "    # Create a copy of the DataFrame\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    # Normalize each joint\n",
        "    for joint_name in joint_mapping.keys():\n",
        "        # Get current range\n",
        "        current_min = np.nanmin(df[joint_name])\n",
        "        current_max = np.nanmax(df[joint_name])\n",
        "\n",
        "        # Skip if range is too small\n",
        "        if np.abs(current_max - current_min) < 1e-6:\n",
        "            continue\n",
        "\n",
        "        # Get target range\n",
        "        target_min, target_max = robot_ranges[joint_name]\n",
        "\n",
        "        # Normalize\n",
        "        normalized_df[joint_name] = (df[joint_name] - current_min) / (current_max - current_min) * (target_max - target_min) + target_min\n",
        "\n",
        "    return normalized_df\n",
        "\n",
        "def downsample_dataframe(df, source_fps, target_fps):\n",
        "    \"\"\"\n",
        "    Downsample a DataFrame from source_fps to target_fps\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame containing motion data\n",
        "        source_fps: Original frame rate\n",
        "        target_fps: Target frame rate\n",
        "\n",
        "    Returns:\n",
        "        Downsampled DataFrame\n",
        "    \"\"\"\n",
        "    # Calculate the downsample factor\n",
        "    downsample_factor = source_fps / target_fps\n",
        "\n",
        "    if downsample_factor == 1:\n",
        "        # No downsampling needed\n",
        "        return df\n",
        "\n",
        "    # Get original frames\n",
        "    original_frames = df['Frame'].values\n",
        "\n",
        "    # Calculate the number of frames in the downsampled data\n",
        "    n_frames_new = int(len(original_frames) / downsample_factor)\n",
        "\n",
        "    # Find all columns except 'Frame'\n",
        "    data_cols = [col for col in df.columns if col != 'Frame']\n",
        "\n",
        "    # Initialize new DataFrame\n",
        "    downsampled_data = {'Frame': np.arange(n_frames_new)}\n",
        "\n",
        "    # Get original time points and new time points\n",
        "    original_time = np.arange(len(df)) / source_fps\n",
        "    new_time = np.arange(n_frames_new) / target_fps\n",
        "\n",
        "    # Resample each column\n",
        "    for col in data_cols:\n",
        "        # Create interpolation function from original data\n",
        "        interpolated = interpolate.interp1d(\n",
        "            original_time,\n",
        "            df[col].values,\n",
        "            kind='linear',\n",
        "            bounds_error=False,\n",
        "            fill_value='extrapolate'\n",
        "        )\n",
        "\n",
        "        # Apply to new time points\n",
        "        downsampled_data[col] = interpolated(new_time)\n",
        "\n",
        "    # Create new DataFrame\n",
        "    downsampled_df = pd.DataFrame(downsampled_data)\n",
        "\n",
        "    return downsampled_df\n",
        "\n",
        "def visualize_joint_data(df, person_id, output_dir):\n",
        "    \"\"\"\n",
        "    Visualize the joint data\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with joint data\n",
        "        person_id: ID of the person\n",
        "        output_dir: Output directory for saving plots\n",
        "    \"\"\"\n",
        "    # Find position columns\n",
        "    position_cols = [col for col in df.columns if col.startswith('Position')]\n",
        "\n",
        "    # Plot joint angles\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, col in enumerate(position_cols):\n",
        "        plt.subplot(4, 2, i+1)\n",
        "        plt.plot(df['Frame'], df[col])\n",
        "        plt.title(f'{col} (radians)')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Angle (rad)')\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'joint_angles_person_{person_id}.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot joint angles in degrees for easier interpretation\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, col in enumerate(position_cols):\n",
        "        plt.subplot(4, 2, i+1)\n",
        "        plt.plot(df['Frame'], np.rad2deg(df[col]))\n",
        "        plt.title(f'{col} (degrees)')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Angle (deg)')\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'joint_angles_degrees_person_{person_id}.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # If velocity columns exist, plot them too\n",
        "    velocity_cols = [col for col in df.columns if col.startswith('Velocity')]\n",
        "\n",
        "    if velocity_cols:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i, col in enumerate(velocity_cols):\n",
        "            plt.subplot(4, 2, i+1)\n",
        "            plt.plot(df['Frame'], df[col])\n",
        "            plt.title(f'{col} (rad/s)')\n",
        "            plt.xlabel('Frame')\n",
        "            plt.ylabel('Angular Velocity (rad/s)')\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, f'joint_velocities_person_{person_id}.png'))\n",
        "        plt.close()\n",
        "\n",
        "    # Create a joint comparison with robot data\n",
        "    try:\n",
        "        # Check if robot data is available\n",
        "        robot_data = pd.read_csv('1_2.csv')\n",
        "\n",
        "        # Plot comparison for each joint\n",
        "        plt.figure(figsize=(15, 15))\n",
        "\n",
        "        for i, col in enumerate(position_cols):\n",
        "            plt.subplot(4, 2, i+1)\n",
        "\n",
        "            # Plot human data\n",
        "            plt.plot(np.arange(len(df)) / len(df), df[col], label='Human (Extracted)')\n",
        "\n",
        "            # Plot robot data (normalized to same length for comparison)\n",
        "            robot_col = col  # Same column name\n",
        "            if robot_col in robot_data.columns:\n",
        "                # Resample robot data to match human data length\n",
        "                robot_x = np.linspace(0, 1, len(robot_data))\n",
        "                human_x = np.linspace(0, 1, len(df))\n",
        "\n",
        "                # Create interpolation function\n",
        "                robot_interp = interpolate.interp1d(\n",
        "                    robot_x,\n",
        "                    robot_data[robot_col].values,\n",
        "                    kind='linear',\n",
        "                    bounds_error=False,\n",
        "                    fill_value='extrapolate'\n",
        "                )\n",
        "\n",
        "                # Resample to human data points\n",
        "                robot_resampled = robot_interp(human_x)\n",
        "\n",
        "                plt.plot(human_x, robot_resampled, '--', label='Robot (Original)')\n",
        "\n",
        "            plt.title(f'{col} Comparison')\n",
        "            plt.xlabel('Normalized Time')\n",
        "            plt.ylabel('Joint Angle (rad)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, f'joint_comparison_person_{person_id}.png'))\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create comparison with robot data: {e}\")\n",
        "\n",
        "def load_robot_data(path):\n",
        "    \"\"\"\n",
        "    Load robot joint data and visualize\n",
        "\n",
        "    Args:\n",
        "        path: Path to the robot joint data CSV\n",
        "    \"\"\"\n",
        "    # Load robot data\n",
        "    robot_df = pd.read_csv(path)\n",
        "\n",
        "    # Find position columns\n",
        "    position_cols = [col for col in robot_df.columns if col.startswith('Position')]\n",
        "\n",
        "    # Plot joint angles\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, col in enumerate(position_cols):\n",
        "        plt.subplot(4, 2, i+1)\n",
        "        plt.plot(robot_df[col])\n",
        "        plt.title(f'{col} (Robot)')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Joint Angle (rad)')\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('robot_joint_angles.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Robot data visualization saved to robot_joint_angles.png\")\n",
        "\n",
        "    return robot_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # First, visualize the robot data to understand its format\n",
        "    robot_df = load_robot_data('1_2.csv')\n",
        "\n",
        "    # Then process the multiperson data\n",
        "    convert_multiperson_data(\n",
        "        input_csv='MultipeopleData2.csv',\n",
        "        output_dir='joint_data',\n",
        "        target_fps=20,\n",
        "        source_fps=30,\n",
        "        normalize=True\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qD-I-HXIJ_R",
        "outputId": "6e0c4ea8-1dd3-4dc5-bc3f-5ce11868f439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robot data visualization saved to robot_joint_angles.png\n",
            "Processing data from MultipeopleData2.csv\n",
            "Found 1 person(s) in the data\n",
            "Saved data for person 1 to joint_data/human_person_1_joints_20hz.csv\n",
            "Original frames: 2728, Downsampled frames: 1818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simplified approach"
      ],
      "metadata": {
        "id": "u9RW44S6LIBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import interpolate\n",
        "\n",
        "def convert_multiperson_data(input_csv, output_dir='joint_data', target_fps=20, source_fps=30, normalize=True):\n",
        "    print(f\"Processing data from {input_csv}\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    persons = df['Person'].unique()\n",
        "\n",
        "    print(f\"Found {len(persons)} person(s) in the data\")\n",
        "\n",
        "    # Define the 7 key joints we want to track (mapped to MediaPipe landmarks)\n",
        "    joint_mapping = {\n",
        "        'Position1': 'Body_17',  # finger\n",
        "        'Position2': 'Body_15',  # wrist\n",
        "        'Position3': 'Body_13',  # elbow\n",
        "        'Position4': 'Body_11',  # shoulder\n",
        "        'Position5': 'Body_23',  # hip\n",
        "        'Position6': 'Body_25',  # knee\n",
        "        'Position7': 'Body_27'   # ankle\n",
        "    }\n",
        "\n",
        "    # Process each person separately\n",
        "    for person_id in persons:\n",
        "        person_df = df[df['Person'] == person_id]\n",
        "\n",
        "        # Get all frames for this person\n",
        "        frames = sorted(person_df['Frame'].unique())\n",
        "\n",
        "        clean_data = {'Frame': frames}\n",
        "\n",
        "        # Dictionary to store joint positions per frame\n",
        "        joints_3d = {}\n",
        "        for joint_name in joint_mapping.keys():\n",
        "            joints_3d[joint_name] = []\n",
        "\n",
        "        # Extract each joint 3D position\n",
        "        for frame in frames:\n",
        "            frame_joints = {}\n",
        "\n",
        "            for joint_name in joint_mapping.keys():\n",
        "                frame_joints[joint_name] = None\n",
        "\n",
        "            frame_data = person_df[person_df['Frame'] == frame]\n",
        "\n",
        "            # Extract joint positions\n",
        "            for joint_name, landmark_name in joint_mapping.items():\n",
        "                joint_row = frame_data[frame_data['Landmark'] == landmark_name]\n",
        "\n",
        "                if not joint_row.empty:\n",
        "                    x, y, z = joint_row['x'].values[0], joint_row['y'].values[0], joint_row['z'].values[0]\n",
        "                    frame_joints[joint_name] = (x, y, z)\n",
        "\n",
        "            for joint_name, pos in frame_joints.items():\n",
        "                joints_3d[joint_name].append(pos)\n",
        "\n",
        "        # Calculate joint angles\n",
        "        joint_angles = calculate_joint_angles(joints_3d)\n",
        "\n",
        "        for joint_name, angles in joint_angles.items():\n",
        "            clean_data[joint_name] = angles\n",
        "\n",
        "        clean_df = pd.DataFrame(clean_data)\n",
        "        clean_df = clean_df.interpolate(method='linear')\n",
        "\n",
        "\n",
        "        # Normalize joint values to match robot range\n",
        "        if normalize:\n",
        "            clean_df = normalize_joint_ranges(clean_df, joint_mapping)\n",
        "\n",
        "        # Downsample\n",
        "        downsampled_df = downsample_dataframe(clean_df, source_fps, target_fps)\n",
        "\n",
        "        output_file = os.path.join(output_dir, f'human_person_{person_id}_joints_{target_fps}hz.csv')\n",
        "        downsampled_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"Saved data for person {person_id} to {output_file}\")\n",
        "        print(f\"Original frames: {len(clean_df)}, Downsampled frames: {len(downsampled_df)}\")\n",
        "\n",
        "def calculate_joint_angles(joints_3d):\n",
        "    joint_angles = {}\n",
        "\n",
        "    for joint_name in joints_3d.keys():\n",
        "        joint_angles[joint_name] = []\n",
        "\n",
        "    n_frames = len(joints_3d['Position1'])\n",
        "\n",
        "    for frame in range(n_frames):\n",
        "        pos1 = joints_3d['Position1'][frame]  # finger\n",
        "        pos2 = joints_3d['Position2'][frame]  # wrist\n",
        "        pos3 = joints_3d['Position3'][frame]  # elbow\n",
        "        pos4 = joints_3d['Position4'][frame]  # shoulder\n",
        "        pos5 = joints_3d['Position5'][frame]  # hip\n",
        "        pos6 = joints_3d['Position6'][frame]  # knee\n",
        "        pos7 = joints_3d['Position7'][frame]  # ankle\n",
        "\n",
        "        if None in [pos1, pos2, pos3, pos4, pos5, pos6, pos7]:\n",
        "            for joint_name in joint_angles.keys():\n",
        "                joint_angles[joint_name].append(np.nan)\n",
        "            continue\n",
        "\n",
        "        # Calculate angles\n",
        "        # Position1: Finger angle (relative to wrist)\n",
        "        finger_vec = np.array(pos1) - np.array(pos2)\n",
        "        wrist_vec = np.array(pos2) - np.array(pos3)\n",
        "        angle1 = angle_between_vectors(finger_vec, wrist_vec)\n",
        "\n",
        "        # Position2: Wrist angle (relative to elbow)\n",
        "        wrist_vec = np.array(pos2) - np.array(pos3)\n",
        "        elbow_vec = np.array(pos3) - np.array(pos4)\n",
        "        angle2 = angle_between_vectors(wrist_vec, elbow_vec)\n",
        "\n",
        "        # Position3: Elbow angle (relative to shoulder)\n",
        "        elbow_vec = np.array(pos3) - np.array(pos4)\n",
        "        shoulder_vec = np.array(pos4) - np.array(pos5)\n",
        "        angle3 = angle_between_vectors(elbow_vec, shoulder_vec)\n",
        "\n",
        "        # Position4: Shoulder angle (3D orientation)\n",
        "        vertical = np.array([0, 1, 0])  # Assuming Y is vertical\n",
        "        angle4 = angle_between_vectors(shoulder_vec, vertical)\n",
        "\n",
        "        # Position5: Hip angle\n",
        "        hip_vec = np.array(pos5) - np.array(pos6)\n",
        "        angle5 = angle_between_vectors(hip_vec, vertical)\n",
        "\n",
        "        # Position6: Knee angle\n",
        "        knee_vec = np.array(pos6) - np.array(pos7)\n",
        "        angle6 = angle_between_vectors(knee_vec, hip_vec)\n",
        "\n",
        "        # Position7: Ankle angle (orientation)\n",
        "        ground_normal = np.array([0, 0, 1])  # Assuming Z is up from ground\n",
        "        angle7 = angle_between_vectors(knee_vec, ground_normal)\n",
        "\n",
        "        # Add to joint angles\n",
        "        joint_angles['Position1'].append(angle1)\n",
        "        joint_angles['Position2'].append(angle2)\n",
        "        joint_angles['Position3'].append(angle3)\n",
        "        joint_angles['Position4'].append(angle4)\n",
        "        joint_angles['Position5'].append(angle5)\n",
        "        joint_angles['Position6'].append(angle6)\n",
        "        joint_angles['Position7'].append(angle7)\n",
        "\n",
        "    return joint_angles\n",
        "\n",
        "def angle_between_vectors(v1, v2):\n",
        "    v1 = np.array(v1)\n",
        "    v2 = np.array(v2)\n",
        "\n",
        "    v1_norm = np.linalg.norm(v1)\n",
        "    v2_norm = np.linalg.norm(v2)\n",
        "\n",
        "    if v1_norm < 1e-10 or v2_norm < 1e-10:\n",
        "        return 0.0\n",
        "\n",
        "    v1 = v1 / v1_norm\n",
        "    v2 = v2 / v2_norm\n",
        "\n",
        "    dot_product = np.clip(np.dot(v1, v2), -1.0, 1.0)\n",
        "    angle = np.arccos(dot_product)\n",
        "\n",
        "    return angle\n",
        "\n",
        "def normalize_joint_ranges(df, joint_mapping):\n",
        "    # Robot joint ranges (in radians)\n",
        "    robot_ranges = {\n",
        "        'Position1': (-2.9, 2.9),    # Joint 1\n",
        "        'Position2': (-1.8, 1.8),    # Joint 2\n",
        "        'Position3': (-2.9, 2.9),    # Joint 3\n",
        "        'Position4': (-3.1, 0.0),    # Joint 4\n",
        "        'Position5': (-2.9, 2.9),    # Joint 5\n",
        "        'Position6': (-0.0, 3.8),    # Joint 6\n",
        "        'Position7': (-2.9, 2.9)     # Joint 7\n",
        "    }\n",
        "\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    # Normalize each joint\n",
        "    for joint_name in joint_mapping.keys():\n",
        "        current_min = np.nanmin(df[joint_name])\n",
        "        current_max = np.nanmax(df[joint_name])\n",
        "\n",
        "        if np.abs(current_max - current_min) < 1e-6:\n",
        "            continue\n",
        "\n",
        "        target_min, target_max = robot_ranges[joint_name]\n",
        "        normalized_df[joint_name] = (df[joint_name] - current_min) / (current_max - current_min) * (target_max - target_min) + target_min\n",
        "\n",
        "    return normalized_df\n",
        "\n",
        "def downsample_dataframe(df, source_fps, target_fps):\n",
        "    downsample_factor = source_fps / target_fps\n",
        "\n",
        "    if downsample_factor == 1:\n",
        "        return df\n",
        "\n",
        "    original_frames = df['Frame'].values\n",
        "    n_frames_new = int(len(original_frames) / downsample_factor)\n",
        "    data_cols = [col for col in df.columns if col != 'Frame']\n",
        "    downsampled_data = {'Frame': np.arange(n_frames_new)}\n",
        "\n",
        "    original_time = np.arange(len(df)) / source_fps\n",
        "    new_time = np.arange(n_frames_new) / target_fps\n",
        "\n",
        "    for col in data_cols:\n",
        "        interpolated = interpolate.interp1d(\n",
        "            original_time,\n",
        "            df[col].values,\n",
        "            kind='linear',\n",
        "            bounds_error=False,\n",
        "            fill_value='extrapolate'\n",
        "        )\n",
        "\n",
        "        downsampled_data[col] = interpolated(new_time)\n",
        "\n",
        "    downsampled_df = pd.DataFrame(downsampled_data)\n",
        "\n",
        "    return downsampled_df\n",
        "\n",
        "\n",
        "convert_multiperson_data(\n",
        "    input_csv='MultipeopleData2.csv',\n",
        "    output_dir='joint_data',\n",
        "    target_fps=20,\n",
        "    source_fps=30,\n",
        "    normalize=True"
      ],
      "metadata": {
        "id": "9IIhALSf2CC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgQQQotjaSb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WwvJ-Q9MaSeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTY-54TtaSjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBjtiotIaSml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low pass filter to reduce noise and make data smoother"
      ],
      "metadata": {
        "id": "P5J9X9-GaSv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def smooth_joint_data(input_csv, output_csv, method='butterworth', cutoff=2.0, order=4, window_size=15):\n",
        "\n",
        "    print(f\"Loading data from {input_csv}\")\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Identify joint position columns\n",
        "    position_cols = [col for col in df.columns if col.startswith('Position')]\n",
        "\n",
        "    # Create a copy for smoothed data\n",
        "    smoothed_df = df.copy()\n",
        "\n",
        "    # Apply the selected smoothing method\n",
        "    if method == 'butterworth':\n",
        "        print(f\"Applying Butterworth filter (cutoff={cutoff}Hz, order={order})\")\n",
        "        # Assume 20Hz sampling rate (adjust if different)\n",
        "        fs = 20.0\n",
        "        # Normalize cutoff frequency\n",
        "        nyquist = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyquist\n",
        "\n",
        "        # Design filter\n",
        "        b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "        # Apply to each joint position\n",
        "        for col in position_cols:\n",
        "            # Apply filtering\n",
        "            smoothed_df[col] = signal.filtfilt(b, a, df[col].values)\n",
        "\n",
        "    elif method == 'savgol':\n",
        "        print(f\"Applying Savitzky-Golay filter (window={window_size}, order={order})\")\n",
        "        # Make sure window_size is odd\n",
        "        if window_size % 2 == 0:\n",
        "            window_size += 1\n",
        "\n",
        "        # Apply to each joint position\n",
        "        for col in position_cols:\n",
        "            smoothed_df[col] = signal.savgol_filter(df[col].values, window_size, order)\n",
        "\n",
        "    elif method == 'moving_avg':\n",
        "        print(f\"Applying Moving Average filter (window={window_size})\")\n",
        "        # Define moving average filter\n",
        "        window = np.ones(window_size) / window_size\n",
        "\n",
        "        # Apply to each joint position\n",
        "        for col in position_cols:\n",
        "            smoothed_df[col] = np.convolve(df[col].values, window, mode='same')\n",
        "\n",
        "            # Fix edges (first and last window_size/2 points)\n",
        "            half_window = window_size // 2\n",
        "            for i in range(half_window):\n",
        "                # Start (use forward values)\n",
        "                if i < len(df):\n",
        "                    forward_window = min(window_size, len(df) - i)\n",
        "                    smoothed_df.loc[i, col] = df[col].values[i:i+forward_window].mean()\n",
        "\n",
        "                # End (use backward values)\n",
        "                end_idx = len(df) - 1 - i\n",
        "                if end_idx >= 0:\n",
        "                    backward_window = min(window_size, len(df) - (len(df) - 1 - i))\n",
        "                    smoothed_df.loc[end_idx, col] = df[col].values[end_idx-backward_window+1:end_idx+1].mean()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown smoothing method: {method}\")\n",
        "\n",
        "    # Recalculate velocities if they exist\n",
        "    velocity_cols = [col for col in df.columns if col.startswith('Velocity')]\n",
        "    if velocity_cols:\n",
        "        print(\"Recalculating velocities from smoothed positions\")\n",
        "\n",
        "        for i, pos_col in enumerate(position_cols):\n",
        "            vel_col = f\"Velocity{pos_col[-1]}\"\n",
        "            if vel_col in velocity_cols:\n",
        "                # Compute velocity using central differences\n",
        "                pos_values = smoothed_df[pos_col].values\n",
        "                vel_values = np.zeros_like(pos_values)\n",
        "\n",
        "                # Interior points (central difference)\n",
        "                vel_values[1:-1] = (pos_values[2:] - pos_values[:-2]) / 2.0\n",
        "\n",
        "                # Endpoints (forward and backward differences)\n",
        "                vel_values[0] = pos_values[1] - pos_values[0]\n",
        "                vel_values[-1] = pos_values[-1] - pos_values[-2]\n",
        "\n",
        "                # Scale by sampling rate (assuming 20Hz)\n",
        "                vel_values *= 20.0\n",
        "\n",
        "                # Update velocity column\n",
        "                smoothed_df[vel_col] = vel_values\n",
        "\n",
        "    # Save smoothed data\n",
        "    print(f\"Saving smoothed data to {output_csv}\")\n",
        "    smoothed_df.to_csv(output_csv, index=False)\n",
        "\n",
        "    return smoothed_df\n",
        "\n",
        "def visualize_smoothing_comparison(original_df, smoothed_df, output_dir, prefix=''):\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Identify joint position columns\n",
        "    position_cols = [col for col in original_df.columns if col.startswith('Position')]\n",
        "\n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, col in enumerate(position_cols):\n",
        "        plt.subplot(4, 2, i+1)\n",
        "        plt.plot(original_df['Frame'], original_df[col], 'r-', alpha=0.5, label='Original')\n",
        "        plt.plot(smoothed_df['Frame'], smoothed_df[col], 'b-', label='Smoothed')\n",
        "        plt.title(f'{col} Comparison')\n",
        "        plt.xlabel('Frame')\n",
        "        plt.ylabel('Joint Angle (rad)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'{prefix}smoothing_comparison.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot velocities if they exist\n",
        "    velocity_cols = [col for col in original_df.columns if col.startswith('Velocity')]\n",
        "    if velocity_cols:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i, col in enumerate(velocity_cols):\n",
        "            plt.subplot(4, 2, i+1)\n",
        "            plt.plot(original_df['Frame'], original_df[col], 'r-', alpha=0.5, label='Original')\n",
        "            plt.plot(smoothed_df['Frame'], smoothed_df[col], 'b-', label='Smoothed')\n",
        "            plt.title(f'{col} Comparison')\n",
        "            plt.xlabel('Frame')\n",
        "            plt.ylabel('Angular Velocity (rad/s)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, f'{prefix}velocity_comparison.png'))\n",
        "        plt.close()\n",
        "\n",
        "def batch_process_joint_files(input_dir, output_dir, method='butterworth',\n",
        "                           cutoff=2.0, order=4, window_size=15, visualize=False):\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Find all CSV files in input directory\n",
        "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
        "\n",
        "    for file in csv_files:\n",
        "        input_path = os.path.join(input_dir, file)\n",
        "        output_path = os.path.join(output_dir, f\"smoothed_{file}\")\n",
        "\n",
        "        print(f\"Processing {file}...\")\n",
        "\n",
        "        # Load original data\n",
        "        original_df = pd.read_csv(input_path)\n",
        "\n",
        "        # Apply smoothing\n",
        "        smoothed_df = smooth_joint_data(\n",
        "            input_path,\n",
        "            output_path,\n",
        "            method=method,\n",
        "            cutoff=cutoff,\n",
        "            order=order,\n",
        "            window_size=window_size\n",
        "        )\n",
        "\n",
        "        # Visualize if requested\n",
        "        if visualize:\n",
        "            visualize_smoothing_comparison(\n",
        "                original_df,\n",
        "                smoothed_df,\n",
        "                output_dir,\n",
        "                prefix=os.path.splitext(file)[0] + '_'\n",
        "            )\n",
        "\n",
        "    print(f\"Processed {len(csv_files)} files\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Option 1: Process a single file\n",
        "    smooth_joint_data(\n",
        "        input_csv='joint_data/3human_person_1_joints_20hz.csv',\n",
        "        output_csv='joint_data/3smoothed_human_person_1_joints_20hz.csv',\n",
        "        method='butterworth',\n",
        "        cutoff=2.0,  # 2Hz cutoff - adjust based on your movement data\n",
        "        order=4      # 4th order filter\n",
        "    )\n",
        "\n",
        "    # Option 2: Batch process all files in a directory\n",
        "    # batch_process_joint_files(\n",
        "    #     input_dir='joint_data',\n",
        "    #     output_dir='smoothed_joint_data',\n",
        "    #     method='butterworth',  # Try 'butterworth', 'savgol', or 'moving_avg'\n",
        "    #     cutoff=2.0,            # Cutoff frequency in Hz (lower = smoother)\n",
        "    #     order=4,               # Filter order (higher = sharper cutoff)\n",
        "    #     window_size=15,        # Window size for savgol or moving average\n",
        "    #     visualize=True         # Create comparison visualizations\n",
        "    # )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byDw30GQaXBP",
        "outputId": "101735f4-1ad6-4105-8df4-22a710bf355b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from joint_data/3human_person_1_joints_20hz.csv\n",
            "Applying Butterworth filter (cutoff=2.0Hz, order=4)\n",
            "Saving smoothed data to joint_data/3smoothed_human_person_1_joints_20hz.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgL7zh_DajaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}